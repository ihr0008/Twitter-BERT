{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparing SVC and BERT for NLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe873c25ac834191aa9e145a52a15664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ed23f73770c436fbab71e902b4009e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abe4287d5d4c45858f2532c1b8d43507",
              "IPY_MODEL_55d73152b3464c929d2c61a5503ba15c"
            ]
          }
        },
        "3ed23f73770c436fbab71e902b4009e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abe4287d5d4c45858f2532c1b8d43507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_298ff207bf30428289b14d273a10c4d2",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16d733e64a294278baabc30db6833d1d"
          }
        },
        "55d73152b3464c929d2c61a5503ba15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca9cc728a9fa4e91a55045d5cbd13f87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 1.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cbd5bd8829d412c9a3acbf6dffe81e6"
          }
        },
        "298ff207bf30428289b14d273a10c4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16d733e64a294278baabc30db6833d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca9cc728a9fa4e91a55045d5cbd13f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cbd5bd8829d412c9a3acbf6dffe81e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZD-AZNvZq8",
        "colab_type": "text"
      },
      "source": [
        "### The Value of Transfer Learning Part I: Using Tweets to Compare SVM and Pre-Trained BERT Classifiers\n",
        "\n",
        " - By [Isaac Revette](https:/https://ihr0008.github.io//)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32TGbOLjazZ6",
        "colab_type": "text"
      },
      "source": [
        "# Introduction:\n",
        " - The purpose of this is to highlight the power of **transfer learning** to help avoid the cold start problem when using deep learning models.\n",
        " - I will be using the State-of-the-art BERT Model released by Google, the description of it is as follows:\n",
        " - \"*Bidirectional Encoder Representations from Transformers is a technique for NLP pre-training developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google. Google is leveraging BERT to better understand user searches.\"*\n",
        " - The classification problem will be identifing whether a tweet is positive or negative.\n",
        " - Enjoy!\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-Go8AFgj7N",
        "colab_type": "text"
      },
      "source": [
        "# To identify whether a tweet is positive or negative, we will:\n",
        " - Train an Support Vector Classifier \n",
        " - Use Sklearn to train and tune the SVC\n",
        " - Use SpaCy to tokenize text for the SVC\n",
        " - Fine Tune a Pre-trained BERT Model  \n",
        " - Use the huggingface Pytorch library to tune the BERT Model\n",
        " - Compare each model on a holdout dataset of tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z-Q1zfpZplc_"
      },
      "source": [
        "### Load the Data from my Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OG3nY8CpldP",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/ihr0008/Twitter-BERT/master/dev.tsv\", sep =\"\\t\", names = ['id', 'label', 'alpha','tweet'],)\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/ihr0008/Twitter-BERT/master/test.tsv\", sep =\"\\t\", names =['id', 'label', 'alpha','tweet'], skiprows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bSJeoMMfpldY",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "tweets = train.tweet.values\n",
        "labels = train.label.values\n",
        "labels = np.where(labels==4, 1, labels) # data has 0 & 4 in it, replace 4 with 1 for understanding\n",
        "test_tweets = test.tweet.values\n",
        "test_labels = test.label.values\n",
        "test_labels = np.where(test_labels==4, 1, test_labels) # data has 0 & 4 in it, replace 4 with 1 for understanding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE2rrE2rlO0U",
        "colab_type": "text"
      },
      "source": [
        "# Training the SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHtAAxaLlidj",
        "colab_type": "code",
        "outputId": "c5e214cc-4b2b-4f8b-e4c5-3e9bef212079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "import spacy.cli\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5faFHenjm4tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the Large English NLP Package\n",
        "print('Be patient, this can take a lil bit...')\n",
        "#spacy.cli.download(\"en_core_web_lg\")\n",
        "\n",
        "# Load the Large English NLP Package of Spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "print('Large English NLP Package loaded successfully!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4OyORGkn6Wv",
        "colab_type": "text"
      },
      "source": [
        "## First we have to create a process to tokenize and format our tweets so the SVC can interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf4YozvRmmJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hYu5pqPn4d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Custom transformer using spaCy\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        # Cleaning Text\n",
        "        return [clean_text(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text\n",
        "def clean_text(text):\n",
        "    # Removing spaces and converting text into lowercase\n",
        "    return text.strip().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IanGUiBDpER5",
        "colab_type": "text"
      },
      "source": [
        "To convert the text to vectors, I will include two ways:\n",
        " - Bag-of-Words with N-gram encoding\n",
        " - Tf-Idf (I will use Tf-Idf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUUAN9qapDVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
        "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvYM08e1qHPu",
        "colab_type": "text"
      },
      "source": [
        "## Create the Pipeline with the SVC to do the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO7akJH0qR40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(random_state=213)\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjCAHOQ1qftY",
        "colab_type": "text"
      },
      "source": [
        "## Split the data into training and test\n",
        " - Split will be 80/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BofNR6wpYWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split tweets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(tweets, labels, \n",
        "                                                            random_state=213, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdovFRx-sALY",
        "colab_type": "text"
      },
      "source": [
        "## Training of the model and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgJByo88stpG",
        "colab_type": "text"
      },
      "source": [
        "### Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABNks73TsGX7",
        "colab_type": "code",
        "outputId": "91769994-c1e3-4a39-a4e5-9f9247ce04f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# model generation\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f89451ba160>),\n",
              "                ('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_wor...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7f885e8a11e0>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzvwgQjXsvri",
        "colab_type": "text"
      },
      "source": [
        "### Predict with the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FsQ7905sHdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predicted = pipe.predict(X_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ep97rx9syYn",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7dZi7r7tul3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Look at the Precision, Recall, F1, and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTtjC_CJs2BP",
        "colab_type": "code",
        "outputId": "fc03c2f7-3234-476d-b3b8-547c1d65ef88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_valid, predicted, digits=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.710     0.737     0.723       749\n",
            "           1      0.756     0.731     0.743       835\n",
            "\n",
            "    accuracy                          0.734      1584\n",
            "   macro avg      0.733     0.734     0.733      1584\n",
            "weighted avg      0.734     0.734     0.734      1584\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9JvFQCbUkO3",
        "colab_type": "text"
      },
      "source": [
        "73% accuracy is not bad for a classifier.\n",
        "\n",
        "Now Lets look at the Mathews Correlation Coefficient:\n",
        " - The scale of the MCC is from -1 to 1\n",
        " - -1 is the worst classifier\n",
        " - +1 is the best classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uMmdkiHUYTn",
        "colab_type": "code",
        "outputId": "ba9f0fd4-0d98-411c-8bc3-debcbe14c041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "mcc = matthews_corrcoef(y_valid, predicted)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51kwgrcHt0dv",
        "colab_type": "text"
      },
      "source": [
        "A decent MCC, its at least above 0.\n",
        "\n",
        "Now lets plot the Area Under the Curve (AUC) / ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi3mkKFJuE03",
        "colab_type": "code",
        "outputId": "7ca5ed1b-bd86-474a-8185-50160089d89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Retrieve the ROC/AUC\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_valid, predicted)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "\n",
        "# Plot the ROC/AUC\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY2KrBh4QAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tihd8KNqtLda",
        "colab_type": "text"
      },
      "source": [
        "The initial Model with no hyper tuning performed well. The red line represents the equivalent of random guessing. The closer the blue line is to be a right angle in the top left, the better the classifier is performing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbGP7fRlUbQ",
        "colab_type": "text"
      },
      "source": [
        "# Tuning the BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG-PE43hhuOc",
        "colab_type": "text"
      },
      "source": [
        "### The first step is to identify the GPU we will use perform the training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiR9NC1BgPty",
        "colab_type": "code",
        "outputId": "04b7eb18-8a40-4827-cc9d-2f236ef7bd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a73RKrjFg3kJ",
        "colab_type": "code",
        "outputId": "af6a4ea5-7ce6-4820-ba05-9d1bb1bae370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "#Look for GPU\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcXWMn1hK-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6UzP2vZn5uz",
        "colab_type": "text"
      },
      "source": [
        "## Next we must tokenize the sentences with  BERTs Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9eiNK3n_wj",
        "colab_type": "code",
        "outputId": "4f94e469-e4e4-4cc0-a20c-c19345c711f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "fe873c25ac834191aa9e145a52a15664",
            "3ed23f73770c436fbab71e902b4009e1",
            "abe4287d5d4c45858f2532c1b8d43507",
            "55d73152b3464c929d2c61a5503ba15c",
            "298ff207bf30428289b14d273a10c4d2",
            "16d733e64a294278baabc30db6833d1d",
            "ca9cc728a9fa4e91a55045d5cbd13f87",
            "7cbd5bd8829d412c9a3acbf6dffe81e6"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe873c25ac834191aa9e145a52a15664",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgUD3--QoSqi",
        "colab_type": "text"
      },
      "source": [
        "Lets test the tokenizer on one tweet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A87mdSQhoK03",
        "colab_type": "code",
        "outputId": "8cc8394e-b551-4409-85fe-94d74e351d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Original Tweet:\n",
        "print(' Original: ', tweets[99])\n",
        "\n",
        "# Split into Tokens:\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[99]))\n",
        "\n",
        "# Token ids:\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[99])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Writing interrupted by French Open tennis. \n",
            "Tokenized:  ['writing', 'interrupted', 'by', 'french', 'open', 'tennis', '.']\n",
            "Token IDs:  [3015, 7153, 2011, 2413, 2330, 5093, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfyiBt5Yq-pE",
        "colab_type": "text"
      },
      "source": [
        "First we have to convert the tweets to Token IDs and add the [CLS] and [SEP] tokens that BERT requires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r-CFJD3ooOP",
        "colab_type": "code",
        "outputId": "d3242f77-b762-4787-f1bc-4d507976dacd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs\n",
        "tweet_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]\n",
        "    )\n",
        "    # Add the encoded sentence to the list\n",
        "    tweet_ids.append(encoded_tweet)\n",
        "\n",
        "# How Tweet and its IDs\n",
        "print('Original: ', tweets[99])\n",
        "print('Token IDs:', tweet_ids[99])\n",
        "\n",
        "# Notice the Token IDs are different then above, thats the [CLS] and [SEP] Tokens\n",
        "# Cool stuff ;)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Writing interrupted by French Open tennis. \n",
            "Token IDs: [101, 3015, 7153, 2011, 2413, 2330, 5093, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bcFxDE0rMlk",
        "colab_type": "text"
      },
      "source": [
        "We now have tweets as Token IDs with the special [CLS] and [SEP] Tokens added. \n",
        "\n",
        "Next we must pad and truncate the tweets so they the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xiO6I7Fq6N-",
        "colab_type": "code",
        "outputId": "ae30fefc-51d1-4fa8-e4bd-2be9fef6f1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Lets check the longest Tweet in our dataset\n",
        "print('Max tweet length: ', max([len(tweet) for tweet in tweet_ids]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max tweet length:  125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUCvCoWPsUqO",
        "colab_type": "text"
      },
      "source": [
        "While in our data the maximum is only 125, I think its worth using 280 because that is how long tweets can be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gjM-nKIs16i",
        "colab_type": "code",
        "outputId": "41e263a4-65ed-4265-aca9-02b19cff8e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Use Keras Pad Sequence function\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Set max length of input \n",
        "MAX_LEN = 284 # I added a few more than 280 just in case\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the tweet\n",
        "tweet_ids = pad_sequences(tweet_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 284 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOvQ4u3CtxWq",
        "colab_type": "text"
      },
      "source": [
        "Now we have to tell BERT what is padding and what is a word using **attention masks**.\n",
        " - We can use 0 to refer to padding because BERT doesnt use that token ID\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21ZEKeZytqhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Attention Masking\n",
        "attention_masks = []\n",
        "\n",
        "for tweet in tweet_ids:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3U6uQvUusZ_",
        "colab_type": "text"
      },
      "source": [
        "## Now we can split our training data into training and validation (90/10):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c53CCSfuk1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split tweets\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(tweet_ids, labels, \n",
        "                                                            random_state=213, test_size=0.1)\n",
        "# Split masks too\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=213, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FB60XtjvaPS",
        "colab_type": "text"
      },
      "source": [
        "## The model needs PyTorch Tensors rather than numpy arrays so we need to convert them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq_j76lCvRUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert to pytorch tensor\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki-SfC8jggRR",
        "colab_type": "text"
      },
      "source": [
        "Create an iterator for the data using the torch DataLoader class to save on memory:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-p5cLtAxWkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training (16 or 32 is recommended)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set:\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data) #Random for training data\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set:\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data) #Sequential for validation data\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L45AeRkRMo2j",
        "colab_type": "text"
      },
      "source": [
        "### If you are going to load the model and not train it, run cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avGA-egHMyer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    # Takes time in seconds and returns a time string (hh:mm:ss)\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edCteVlBxu3s",
        "colab_type": "text"
      },
      "source": [
        "## Now we begin the process of tuning our Pre-trained BERT Model. \n",
        " - We will use huggingface's BertForSequenceClassification model\n",
        " - This will take a while (1 hour for me)\n",
        " - If you have model saved already, do not run this and skip to loading further down\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhapfLQix2Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# Initial Model\n",
        "initial_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab and base (small) size\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification (You can increase this for multi-class tasks)  \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "\n",
        "# Tell pytorch to run this model on the GPU\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyuXSNhczkpS",
        "colab_type": "text"
      },
      "source": [
        "### We can decide our optimization and learning rates for the model.\n",
        " - We will use a learning rate of 2e-5 \n",
        " - For our Optimizer, we will use the AdamW optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OCCSw5j0zaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the AdamW optimizer from huggingface\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 # a small number to prevent any division by 0\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgKwIZ2V1Edh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs (we chose a batch size of 32 so 32*4)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXXfisvh16rr",
        "colab_type": "text"
      },
      "source": [
        "Heres a function to help define accuracy and format time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbi75R-D19AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    # Takes time in seconds and returns a time string (hh:mm:ss)\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruLMfmFW2A1o",
        "colab_type": "text"
      },
      "source": [
        "### This is the training loop for the model, note:\n",
        " - There is a lot going, but most of it is to make it pretty.\n",
        " - I did not write this loop code from scratch, its based on the run_glue.py script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJnIZ4A82b42",
        "colab_type": "code",
        "outputId": "571ebb5e-9237-4937-c996-d838c9022067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed = 213\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    initial_model.train()\n",
        "\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        initial_model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = initial_model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(initial_model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    initial_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = initial_model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    446.    Elapsed: 0:01:04.\n",
            "  Batch    80  of    446.    Elapsed: 0:02:12.\n",
            "  Batch   120  of    446.    Elapsed: 0:03:19.\n",
            "  Batch   160  of    446.    Elapsed: 0:04:26.\n",
            "  Batch   200  of    446.    Elapsed: 0:05:34.\n",
            "  Batch   240  of    446.    Elapsed: 0:06:41.\n",
            "  Batch   280  of    446.    Elapsed: 0:07:48.\n",
            "  Batch   320  of    446.    Elapsed: 0:08:56.\n",
            "  Batch   360  of    446.    Elapsed: 0:10:03.\n",
            "  Batch   400  of    446.    Elapsed: 0:11:10.\n",
            "  Batch   440  of    446.    Elapsed: 0:12:18.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:12:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:31\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    446.    Elapsed: 0:01:07.\n",
            "  Batch    80  of    446.    Elapsed: 0:02:15.\n",
            "  Batch   120  of    446.    Elapsed: 0:03:22.\n",
            "  Batch   160  of    446.    Elapsed: 0:04:29.\n",
            "  Batch   200  of    446.    Elapsed: 0:05:37.\n",
            "  Batch   240  of    446.    Elapsed: 0:06:44.\n",
            "  Batch   280  of    446.    Elapsed: 0:07:51.\n",
            "  Batch   320  of    446.    Elapsed: 0:08:58.\n",
            "  Batch   360  of    446.    Elapsed: 0:10:06.\n",
            "  Batch   400  of    446.    Elapsed: 0:11:13.\n",
            "  Batch   440  of    446.    Elapsed: 0:12:20.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:12:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:31\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    446.    Elapsed: 0:01:07.\n",
            "  Batch    80  of    446.    Elapsed: 0:02:15.\n",
            "  Batch   120  of    446.    Elapsed: 0:03:22.\n",
            "  Batch   160  of    446.    Elapsed: 0:04:29.\n",
            "  Batch   200  of    446.    Elapsed: 0:05:36.\n",
            "  Batch   240  of    446.    Elapsed: 0:06:44.\n",
            "  Batch   280  of    446.    Elapsed: 0:07:51.\n",
            "  Batch   320  of    446.    Elapsed: 0:08:58.\n",
            "  Batch   360  of    446.    Elapsed: 0:10:06.\n",
            "  Batch   400  of    446.    Elapsed: 0:11:13.\n",
            "  Batch   440  of    446.    Elapsed: 0:12:20.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:12:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:31\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    446.    Elapsed: 0:01:07.\n",
            "  Batch    80  of    446.    Elapsed: 0:02:15.\n",
            "  Batch   120  of    446.    Elapsed: 0:03:22.\n",
            "  Batch   160  of    446.    Elapsed: 0:04:29.\n",
            "  Batch   200  of    446.    Elapsed: 0:05:37.\n",
            "  Batch   240  of    446.    Elapsed: 0:06:44.\n",
            "  Batch   280  of    446.    Elapsed: 0:07:51.\n",
            "  Batch   320  of    446.    Elapsed: 0:08:58.\n",
            "  Batch   360  of    446.    Elapsed: 0:10:06.\n",
            "  Batch   400  of    446.    Elapsed: 0:11:13.\n",
            "  Batch   440  of    446.    Elapsed: 0:12:20.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:12:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:32\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJxvcXEcDay8",
        "colab_type": "text"
      },
      "source": [
        "## Save the Model:\n",
        "*Code imported from run_glue.py*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJO_WbUoDgu9",
        "colab_type": "code",
        "outputId": "6e8920da-bf24-4b09-c1f6-5f0a7280a803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAVDWcs-D10D",
        "colab_type": "code",
        "outputId": "2be0ea7f-58fc-4d90-e68d-51a051d3eb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Save to Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Hxul1lD7fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r ./model_save/ \"./drive/My Drive/Saved Models/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuoCnR7EspFC",
        "colab_type": "text"
      },
      "source": [
        "## Predictions and Evaluation from the Tuned BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDLizfBAzPBZ",
        "colab_type": "text"
      },
      "source": [
        "### Process Holdout Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soRzOlvhsuZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test data is test_tweets and test_labels\n",
        "\n",
        "input_ids = []\n",
        "\n",
        "\n",
        "for tweet in test_tweets:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Same Max Length as above - 284\n",
        "MAX_LEN = 284\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjdzMJBh2fMd",
        "colab_type": "text"
      },
      "source": [
        "### Load the Model from Google Drive (so we dont have to retrain)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXvdnHs2kfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "model_dir = \"./drive/My Drive/Saved Models/model_save/\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuPfbGwT3T1f",
        "colab_type": "text"
      },
      "source": [
        "### Getting Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikzFV3FG3cxk",
        "colab_type": "code",
        "outputId": "4ea0cc86-aca2-4275-d5ba-8d4e2ca9dba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "\n",
        "print('Predicting labels for {:,} test tweets...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 15,682 test tweets...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PM6ILryV_4I",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate BERT Model\n",
        "\n",
        " - taking predictions from the BERT is a bit tricky because the output in this case is the logit prediction of the texts semantic meaning\n",
        " - we have to convert all of it to one array of predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1FnwpoRWjKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0 and 1 preds\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AelLJldtWt3T",
        "colab_type": "text"
      },
      "source": [
        "Lets look at the Precision, Recall, F1, and Accuracy Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2DwaR-W3W9",
        "colab_type": "code",
        "outputId": "90d4a9cb-0871-4801-ba8d-8fa2fb21baa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(flat_true_labels, flat_predictions, digits=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.831     0.831     0.831      7862\n",
            "           1      0.830     0.830     0.830      7820\n",
            "\n",
            "    accuracy                          0.830     15682\n",
            "   macro avg      0.830     0.830     0.830     15682\n",
            "weighted avg      0.830     0.830     0.830     15682\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJRb3S3KW9FJ",
        "colab_type": "text"
      },
      "source": [
        "83%! Thats around 10% better than the SVC we trained. The model is around 20% better than the SVC at predicting the semantic labels when compared to random (50%).\n",
        "\n",
        "Lets Look at the Matthews Correlation Coefficient now\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPMWvuK-T-KR",
        "colab_type": "code",
        "outputId": "07109bf0-4fe7-4a56-d66d-ebd9b023d9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZIJo2agv4rDZ"
      },
      "source": [
        "0.661 is pretty good, up from .467 with the SVC\n",
        "\n",
        "Now we can plot the Area Under the Curve (AUC) / ROC Curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c941061d-5e7f-46fc-8aa9-9debe9e0c2a0",
        "id": "Ayakzb144rDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Retrieve the ROC/AUC\n",
        "fpr, tpr, threshold = metrics.roc_curve(flat_true_labels, flat_predictions)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "\n",
        "# Plot the ROC/AUC\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni8kThXPOuZg8UTjnnIvp/wEpUNidr9ELnwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y-ZF2G764rDf"
      },
      "source": [
        "Thats a pretty nice looking ROC Curve, right there! Especially considering the model was only trained on 15000 tweets. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-7tIkWWXyTD",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion and Insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIXA00LPX1mG",
        "colab_type": "text"
      },
      "source": [
        "### *Heres a few considerations before I draw insights:*\n",
        " - *The SVC performed well and could have performed better if I spent a good amount of time hyper tuning the parameters.*\n",
        " - *The BERT model is the base/small version and it could have been tuned a little more if I had the time and knowledge to do so.*\n",
        " - *I am by no means an expert in using BERT for NLP, rather I am a data science student with significant room to improve.*\n",
        " - *I used various online and academic resources to build this project and was by no means done on my own.*\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr-bpBsCdB3A",
        "colab_type": "text"
      },
      "source": [
        "### Comparatively, our predictions are incredibly accurate for only training on 15000 tweets.\n",
        " - For example, the [Kaggle Competition](https://www.kaggle.com/c/epfml-text/leaderboard) winner for semantic analysis of tweets achieved a validation score of **87.66%** (albeit 3 years ago). As well, they trained on **2.5 million** tweets, compared to our **15000**. \n",
        " - Considering that, I hope you begin to realize the power of transfer learning combined with the state-of-the-art models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEvQTPusYW_6",
        "colab_type": "text"
      },
      "source": [
        "### This project really highlights the power of Transfer learning for several reasons:\n",
        " - Most non-neural net models are pretty good when being trained on lower amounts of training data (less than 100,000 maybe) when compared to neural nets (which require a lot of data to really get good, but scale much better with more information).\n",
        " - Because of taking a pre-trained model and tuning only the top layer or neurons on this specific task, we can use the power of neural nets with limited amounts of data.\n",
        " - Transfer learning helps avoid the **Cold-start problem** that comes with neural nets, meaning we dont have to spend enourmous amounts of **time** and **moeny** to train a top of the line neural net from scratch.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE02G3lsZvXk",
        "colab_type": "text"
      },
      "source": [
        "### By using transfer learning, people and companies can utilize state-of-the-art deep learning models to make predictions without having to obtain enourmous amounts of data to train them.\n",
        " - All you need is a pretrained model and you can implement it on limited data problems.\n",
        " - This can help companies without a history of data collection or within new industries utilize the best machine learning algorithms like never before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMuNfDYzagol",
        "colab_type": "text"
      },
      "source": [
        "### All that being said, the more we train this model the better it will do! That takes time and money I do not have as a graduate student (at the time of this writing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLaRYa2iawGB",
        "colab_type": "text"
      },
      "source": [
        "# Thank you!"
      ]
    }
  ]
}